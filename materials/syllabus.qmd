---
title: "Syllabus"
format:
  html:
    toc: true
    toc-depth: 4
---

## General Information

**Term/Year:** 2025/2026<br>
**Subject Code and Course Number:** [#856; #867] <br>
**Course Title:** Data Analytics<br>
**Instructor:** Karen Hovhannisyan<br>
**Email:** khovhannisyan91@gmail.com <br>
**Phone:** +374 77 600 945<br>
**Start date:** 18-12-2025<br>
**End date:** 01-05-2026<br>
**Class Schedule:**  
  - Tuesdays 19:30–22:00, Saturdays 15:00–17:30 (Cohort #856)  
  - Thursdays 18:30–21:00, Sundays 10:00–12:30 (Cohort #867)  
**Materials:** [Reading Materials](https://drive.google.com/drive/folders/1pe4DpaGob4K84rEfIsvVXS8WAT4qYtnG?usp=drive_link)<br>
**Technical stack:** `excel`, `PostgreSQL`, `Python` (Data Analytics toolpack), `Tableau`, `Docker`, `Git`<br>
**Prerequisites:** Curiosity; Analytical Thinking<br>

## Schedule & Topics

### Introduction to Data Analytics & Statistical Thinking

> - **Duration:** 4 weeks (8 sessions / 20 hours)
> - **Goal:** Build analytical thinking and statistics foundation before tools. Adding light visualization early so students see value in data storytelling immediately.

#### Week 1: Foundations of Analytics & Data Thinking

- Getting familiarized with each other  
- Course logistics  
- What is data analytics? Real business use cases  
- Types of analytics (descriptive, predictive, prescriptive)  
- Data lifecycle and roles (Analyst, Engineer, Scientist)  
- Understanding data sources and structures 
- Hands-on: Map the data analytics process for a telecom or retail case  

#### Week 2: Descriptive Statistics + Intro to Data Visualization

- Types of data  
- Mean, median, mode  
- Variance, standard deviation  
- Histogram, bar chart, box plot  
- When to use each chart type  
- Hands-on: basic charts in Excel or Sheets  
- Hands-on: summarize dataset (`pandas describe`)  

#### Week 3: Probability & Distributions + Visualizing Distributions

- Probability basics  
- Normal, Binomial, Poisson distributions  
- CLT, z-scores, outliers  
- Visualizing distributions: hist, KDE, scatter, density plots  
- Hands-on: dice/coin simulations in Python or Excel  

#### Week 4: Inference & Analytical Thinking + Visual Storytelling

- Sampling methods  
- Confidence intervals, margin of error  
- Hypothesis testing (`t-test`, `chi-square`)  
- Interpreting `p-values` and effect size  
- Bias
- Storytelling with charts  
- Mini project: GameCo analysis  

---

### SQL 

> - **Duration:** 6 weeks (12 sessions / 30 hours)
> - **Goal:** Build solid SQL and database skills by designing schemas, querying data, performing analytical transformations, and working with real PostgreSQL environments to support end-to-end analytics workflows

#### Week 1: Environment Setup — Part 1

- Install Docker Desktop  
- Pull & run PostgreSQL container  
- Install pgAdmin or configure `psql`  
- Install VS Code + DB/Git extensions  
- Install Git, create GitHub account  
- Create project folder structure  
- Initialize Git repo  
- Verify DB connection  

#### Week 2: Environment Setup — Part 2 + SQL Kickoff

- Postgres lifecycle in Docker  
- Basic PostgreSQL config  
- Schemas, tables  
- Insert sample rows  
- SELECT statements  
- Load CSV to DB  

#### Week 3: Filtering, Aggregation, and Grouping

- SELECT, WHERE, ORDER BY, DISTINCT  
- SUM, AVG, COUNT, MIN, MAX  
- GROUP BY, HAVING  
- CASE, COALESCE, CAST  
- Commit SQL to GitHub  

#### Week 4: Joins, Subqueries, and CTEs

- Keys & relationships  
- INNER, LEFT, RIGHT, FULL  
- Subqueries  
- CTEs for pipelines  
- Export results to CSV  

#### Week 5: Window Functions & Analytical Scenarios

- OVER() clause  
- RANK, ROW_NUMBER, DENSE_RANK  
- Running totals, moving averages, lag/lead  
- Telecom churn & retention cases  
- ERD + data dictionary  

#### Week 6: Functions, Procedures, and Advanced Aggregations

- Stored procedures & UDFs  
- Parameterized queries  
- CUBE, ROLLUP, GROUPING SETS  
- Materialized views  

---

### Python for Data Analytics

> - **Duration:** 7 weeks (14 sessions / 35 hours)
> - **Goal:** Learn to connect data sources, build analytical visualizations, and design interactive dashboards that communicate insights effectively for business decisions.

#### Week 1: Python Fundamentals & Environment Setup

- Install Miniconda  
- Create environment  
- Install pandas, numpy, matplotlib, seaborn, psycopg2  
- Install Jupyter Notebook  
- Connect Python ↔ PostgreSQL  
- Python basics: syntax, loops, functions, types  
- Run notebooks and scripts  

#### Week 2: pandas & Data Visualization

- Load, clean, transform datasets  
- `describe`, `info`, `shape`, `value_counts`  
- Aggregation, filtering, merging  
- Visualizations: hist, bar, box, line charts  

#### Week 3: A/B Testing & Regression

- Experiments, control/treatment  
- Hypothesis testing, p-values  
- t-test in Python  
- Linear regression (scikit-learn)  
- R², coefficients, interpretation  

#### Week 4: Clustering & Segmentation

- K-Means clustering  
- Elbow method  
- Visualizing clusters  
- Business segmentation interpretation  

#### Week 5: SQLAlchemy Integration

- Connect Python & PostgreSQL via SQLAlchemy  
- Read SQL tables into pandas  
- Execute SQL from Python  
- Write processed data back to DB  

#### Week 6: Streamlit Fundamentals + Prototyping

- Intro to Streamlit: layout, widgets, state  
- Project structure for apps (`app.py`, `pages/`, `assets/`)  
- Connect to PostgreSQL from Streamlit (SQLAlchemy)  
- Display DataFrames, filters, and basic charts  
- Caching data queries and expensive operations  
- Prototype: single‑page KPI dashboard  

#### Week 7: Final Streamlit Data Dashboard

- Design multi‑page app (navigation via pages/)  
- Interactive filtering, parameters, and URL/query state  
- Charts with seaborn/matplotlib or Plotly; export to CSV  
- Session state, forms, and callbacks for smooth UX  
- Environment configs (.env) and secrets management  
- Optional deployment: Streamlit Community Cloud or Docker  
- Deliverable: Final dashboard demo with README instructions  

---

### Tableau

> - **Duration:** 4 weeks (8 sessions / 20 hours)
> - **Goal:** Develop hands-on expertise in data visualization and dashboard design, connecting to real data sources and building interactive, business-ready dashboards. 

#### Week 1: Intro

- Connect to basic data sources (Excel, CSV)
- Workbooks
- Data types
- Dimensions vs. Measures
- Discrete vs. Continuous fields
- Tableau interface (shelves, marks, filters, dashboards, buttons)
- Create basic charts: bar, line, pie, scatter
- Use filters, groups, sets, and sorting
- Task: Publish your first simple dashboard

#### Week 2: Intermediate Visual Analytics

- Connect to databases (PostgreSQL)
- Work with data joins, blends, unions, and relationships
- Get CSV from SQL Stored Procedure using Python
- Dual-axis charts, histograms, boxplots, heatmaps
- Calculated fields (row-level vs aggregate)
- Parameters (interactive filtering)
- Types of filters (including dashboard actions)
- Task: Build dashboards with interactivity (actions, filters, tooltips)

#### Week 3: Advanced Analytics

- Complex Calculations
- Table calculations (running totals, percent of total, rank)
- Date functions
- Date parameters
- Level of Detail (LOD) expressions (FIXED, INCLUDE, EXCLUDE)
- Cohort and retention analysis in Tableau
- Spatial Analytics, spatial joins
- Spatial functions, connecting to Google Maps
- Data Modeling
- Data prep with Tableau Prep
- Cleaning and reshaping data
- Build dashboards for KPIs, cohort tables, and advanced heatmaps
- Work on telecom/finance/marketing datasets

#### Week 4: Dashboard Design & Performance

- Design Principles
- Visual best practices (color, layout, storytelling)
- Types of dashboards
- Interactive dashboards
- Performance Optimization
- Reduce extract size
- Optimize calculations
- Minimize dashboard load time
- Task: Build an end-to-end business dashboard (filters, parameters, highlights) and add interactivity (URL actions, sheet swapping)

---

### Capstone

> - **Duration:** 3 weeks (8 sessions / 15 hours)
> - **Goal:** Build and present a complete data analytics project demonstrating end-to-end skills across data modeling, ETL, SQL analysis, Python insights, and dashboard storytelling.


1. **Problem Definition:** Identify business question
2. **Data Planning & Schema Design:** Define ERD & tables
3. **ETL using Python:** Extract, clean, and load data to SQL
4. **Analytical Layer (SQL):** Create stored procedures, summary tables
5. **Exploration & Predictive Analytics (Python):** Analyze and model data
6. **Export Final Data (CSV):** prepare dataset for visualization
7. **Dashboard Creation (Tableau):** Final visual storytelling
